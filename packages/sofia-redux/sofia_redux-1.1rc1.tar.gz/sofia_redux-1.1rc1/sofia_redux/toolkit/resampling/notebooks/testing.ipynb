{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "from astropy.stats import gaussian_fwhm_to_sigma as g2s\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "from pypeutils.resampling.resample import *\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "# pyredux needs to be installed\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", ImportError)\n",
    "    from redux.sofia.fifils_reduction import FIFILSReduction\n",
    "    \n",
    "# pyfifi needs to be installed\n",
    "from fifi_ls.resample import combine_files, get_grid_info\n",
    "\n",
    "files = glob.glob('/Users/dperera/test_data/pacman/reduce/*RED_WSH*.fits')\n",
    "outfile = 'pacman.fits'\n",
    "framei = 35\n",
    "# files = glob.glob('/Users/dperera/test_data/fifi-ls/large_wsh/*WSH*.fits')\n",
    "# outfile = 'large.fits'\n",
    "# framei = 21\n",
    "red = FIFILSReduction()\n",
    "red.load(files)\n",
    "red.load_parameters()\n",
    "hduls = red.input\n",
    "param = red.get_parameter_set()\n",
    "save = param.get_value('save')\n",
    "error_weighting = param.get_value('error_weighting')\n",
    "xy_oversample = param.get_value('xy_oversample')\n",
    "w_oversample = param.get_value('w_oversample')\n",
    "xy_order = param.get_value('xy_order')\n",
    "w_order = param.get_value('w_order')\n",
    "xy_window = param.get_value('xy_window')\n",
    "w_window = param.get_value('w_window')\n",
    "xy_smoothing = param.get_value('xy_smoothing')\n",
    "w_smoothing = param.get_value('w_smoothing')\n",
    "fitthresh = param.get_value('fitthresh')\n",
    "posthresh = param.get_value('posthresh')\n",
    "negthresh = param.get_value('negthresh')\n",
    "xythresh = param.get_value('xy_edge_threshold')\n",
    "wthresh = param.get_value('w_edge_threshold')\n",
    "\n",
    "#######\n",
    "xy_order = 2\n",
    "#######\n",
    "\n",
    "order = xy_order, xy_order, w_order\n",
    "edge_threshold = xythresh, xythresh, wthresh\n",
    "window = xy_window, xy_window, w_window\n",
    "oversample = xy_oversample, w_oversample\n",
    "smoothing = xy_smoothing, xy_smoothing, w_smoothing\n",
    "\n",
    "robust = None\n",
    "neg_threshold = None\n",
    "fit_threshold = 0\n",
    "edge_mode = 'edges'\n",
    "fix_order = True\n",
    "write = False\n",
    "\n",
    "combined = combine_files(hduls)\n",
    "grid_info = get_grid_info(combined, oversample=oversample)\n",
    "grid = grid_info['grid']\n",
    "\n",
    "fit_wdw = (window[0] * grid_info['xy_fwhm'],\n",
    "           window[1] * grid_info['xy_fwhm'],\n",
    "           window[2] * grid_info['wave_fwhm'])\n",
    "\n",
    "flxvals = np.hstack([f.ravel() for f in combined['FLUX']])\n",
    "errvals = np.hstack([e.ravel() for e in combined['ERROR']])\n",
    "\n",
    "settings = {'smoothing': smoothing, 'fit_threshold': fit_threshold,\n",
    "            'error_weighting': error_weighting,\n",
    "            'edge_algorithm': 'com_distance',\n",
    "            'edge_threshold': edge_threshold,\n",
    "            'get_error': True, 'get_counts': True,\n",
    "            'jobs': -2}\n",
    "\n",
    "resampler = Resample(grid_info['coordinates'].copy(), flxvals, error=errvals,\n",
    "                     fix_order=fix_order, window=fit_wdw, order=order, robust=None,\n",
    "                     negthresh=None, mode=edge_mode)\n",
    "self = resampler\n",
    "fit_threshold = 0\n",
    "edge_algorithm = 'com_distance'\n",
    "relative_smooth = False\n",
    "error_weighting = False\n",
    "get_error = True\n",
    "jobs = -1\n",
    "client = None\n",
    "cval = np.nan\n",
    "fwhm = grid_info['xy_fwhm'], grid_info['xy_fwhm'], grid_info['wave_fwhm']\n",
    "smoothing = g2s * fwhm[0], g2s * fwhm[1], 0.25 * fwhm[2]  # fwhm or alpha\n",
    "adaptive_threshold = 1, 1, 0\n",
    "get_covar = False\n",
    "mise = True\n",
    "cross_validate = False\n",
    "is_covar = False\n",
    "fast_error = True\n",
    "\n",
    "settings = self.reduction_settings(\n",
    "    smoothing, fit_threshold, cval, edge_threshold, edge_algorithm,\n",
    "    relative_smooth, error_weighting,\n",
    "    adaptive_threshold, is_covar, fast_error, jobs, client)\n",
    "\n",
    "\n",
    "grid = grid_info['grid']\n",
    "args = grid\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "import bottleneck as bn\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "import warnings\n",
    "from pypeutils.resampling.resample import scale_coordinates\n",
    "from pypeutils.resampling.resample import ResampleGrid\n",
    "from pypeutils.resampling.resample_utils import gaussian_matrix\n",
    "\n",
    "def imshow(val): \n",
    "        plt.imshow(val[0].reshape(visitor_grid.shape)[framei]) \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "result = resampler(*grid if not cross_validate else grid_info['coordinates'].copy(),\n",
    "                   smoothing=smoothing,\n",
    "                   adaptive_threshold=adaptive_threshold,\n",
    "                   error_weighting=True, jobs=-1)\n",
    "\n",
    "if cross_validate:\n",
    "    args = (grid_info['coordinates'].copy(),)\n",
    "else:\n",
    "    args = grid\n",
    "\n",
    "self._check_call_arguments(*args, smoothing=smoothing,\n",
    "                   edge_algorithm=edge_algorithm,\n",
    "                   edge_threshold=edge_threshold)\n",
    "\n",
    "visitor_grid = ResampleGrid(\n",
    "    *args, tree_shape=self.local_tree.tree_shape,\n",
    "    build_tree=True, scale_factor=self._radius,\n",
    "    scale_offset=self._scale_offsets, dtype=np.float64)\n",
    "\n",
    "get_error=True\n",
    "get_counts=True\n",
    "get_weights=True\n",
    "get_rchi2=True\n",
    "data = self.data\n",
    "error = self.error\n",
    "mask = self.mask\n",
    "\n",
    "adaptive = settings['adaptive_threshold']\n",
    "do_adaptive = adaptive is not None\n",
    "if do_adaptive:\n",
    "    adaptive = np.atleast_1d(adaptive).astype(float)\n",
    "    if adaptive.size == 0 or np.allclose(adaptive, 0):\n",
    "        do_adaptive = False\n",
    "\n",
    "if not do_adaptive:\n",
    "    settings['adaptive_threshold'] = None\n",
    "    settings['adaptive_alpha'] = np.empty((0, 0, 0))\n",
    "\n",
    "if settings['order_symmetry']:\n",
    "    o = settings['order'][0]\n",
    "else:\n",
    "    o = settings['order']\n",
    "\n",
    "visitor_tree = visitor_grid.tree\n",
    "visitor_tree.set_order(o, order_required=settings['order_required'],\n",
    "                       method=settings['order_method'])\n",
    "visitor_tree.precalculate_powers()\n",
    "\n",
    "required = settings['order_required']\n",
    "local_tree = self.local_tree\n",
    "block = 274  # 183 in data domain\n",
    "local_powers = local_tree.powers\n",
    "visitor_powers = visitor_tree.powers\n",
    "local_coordinates = local_tree.coordinates\n",
    "power_order_idx = local_tree.power_order_idx\n",
    "from pypeutils.resampling.resample_utils import check_edges \n",
    "get_distance_weights = False\n",
    "principle_idx = self.local_tree.principle_indices\n",
    "get_cov = True\n",
    "\n",
    "visitor_members, visitor_coordinates = visitor_tree.block_members(\n",
    "    block, get_locations=True)\n",
    "\n",
    "local_members = local_tree.query_radius(\n",
    "    visitor_coordinates, 1.0, return_distance=False)\n",
    "\n",
    "\n",
    "###### TREE INTERSECTION\n",
    "\n",
    "n_sets = data.shape[0]\n",
    "features = local_coordinates.shape[0]\n",
    "n_visitors = visitor_members.size\n",
    "fit_out = np.empty((n_sets, n_visitors))\n",
    "\n",
    "if get_error:\n",
    "    error_out = np.empty((n_sets, n_visitors))\n",
    "else:\n",
    "    error_out = fit_out\n",
    "\n",
    "if get_counts:\n",
    "    counts_out = np.empty((n_sets, n_visitors), dtype=np.int64)\n",
    "else:\n",
    "    counts_out = fit_out\n",
    "\n",
    "if get_weights:\n",
    "    weights_out = np.empty((n_sets, n_visitors), dtype=np.float64)\n",
    "else:\n",
    "    weights_out = fit_out\n",
    "\n",
    "if get_distance_weights:\n",
    "    distance_weights_out = np.empty((n_sets, n_visitors), dtype=np.float64)\n",
    "else:\n",
    "    distance_weights_out = fit_out\n",
    "\n",
    "if get_rchi2:\n",
    "    rchi2_out = np.empty((n_sets, n_visitors), dtype=np.float64)\n",
    "else:\n",
    "    rchi2_out = fit_out\n",
    "\n",
    "if get_cov:\n",
    "    cov_out = np.zeros((n_sets, n_visitors, features, features),\n",
    "                       dtype=np.float64)\n",
    "else:\n",
    "    cov_out = np.empty((1, 0, 0, 0))\n",
    "\n",
    "error_weighting = settings['error_weighting']\n",
    "distance_weighting = settings['distance_weighting']\n",
    "alpha = settings['alpha']\n",
    "adaptive_alpha = settings['adaptive_alpha']\n",
    "order = settings['order']\n",
    "order_required = settings['order_required']\n",
    "order_varies = settings['order_varies']\n",
    "minimum_points = settings['order_minpoints']\n",
    "order_algorithm_idx = settings['order_algorithm_idx']\n",
    "fit_threshold = settings['fit_threshold']\n",
    "is_covar = settings['is_covar']\n",
    "order_is_zero = settings['order_is_zero']\n",
    "check_order0 = settings['check_order0']\n",
    "cval = settings['cval']\n",
    "edge_threshold = settings['edge_threshold']\n",
    "edge_algorithm_idx = settings['edge_algorithm_idx']\n",
    "have_error = settings['have_error']\n",
    "fast_error = settings['fast_error']\n",
    "\n",
    "visitor_id = 0\n",
    "\n",
    "visitor = visitor_members[visitor_id]\n",
    "local_submembers = local_members[visitor_id]\n",
    "\n",
    "############# SOLVE VISITOR\n",
    "\n",
    "\n",
    "nsets = data.shape[0]\n",
    "local_subcoord = local_coordinates[:, local_submembers]\n",
    "visitor_subcoord = visitor_coordinates[:, visitor_id]\n",
    "\n",
    "check_edges(edge_algorithm_idx, local_subcoord,\n",
    "            visitor_subcoord, edge_threshold)\n",
    "\n",
    "\n",
    "if adaptive_alpha.size == 0:\n",
    "    adaptive_smoothing = False\n",
    "    dweights = calculate_distance_weights(\n",
    "        local_subcoord, visitor_subcoord, alpha)\n",
    "    adaptive_dweights = np.empty((0, 0))\n",
    "else:\n",
    "    adaptive_smoothing = True\n",
    "    dweights = alpha\n",
    "    adaptive_dweights = calculate_adaptive_distance_weights(\n",
    "        local_subcoord, visitor_subcoord, local_submembers, adaptive_alpha)\n",
    "\n",
    "from pypeutils.resampling.resample_utils import calculate_distance_weights\n",
    "# Calculate distance weights if needed (not needed: alpha = [0])\n",
    "if adaptive_alpha.size == 0:\n",
    "    adaptive_smoothing = False\n",
    "    dweights = calculate_distance_weights(\n",
    "        local_subcoord, visitor_subcoord, alpha)\n",
    "    adaptive_dweights = np.empty((0, 0))\n",
    "else:\n",
    "    adaptive_smoothing = True\n",
    "    dweights = alpha\n",
    "    adaptive_dweights = calculate_adaptive_distance_weights(\n",
    "        local_subcoord, visitor_subcoord, local_submembers, adaptive_alpha)\n",
    "\n",
    "# Arrays for all datasets within window region\n",
    "subdata = data[:, local_submembers]\n",
    "submask = mask[:, local_submembers]\n",
    "sublocal_powers = local_powers[:, local_submembers]\n",
    "subvisitor_powers = visitor_powers[:, visitor]\n",
    "variable_error = error.shape[1] > 1\n",
    "if variable_error:\n",
    "    suberror = error[:, local_submembers]\n",
    "else:\n",
    "    suberror = error  # This is expanded in prune_equation_arrays\n",
    "\n",
    "# Determine whether to check fits and what to do with failures\n",
    "check_fit = fit_threshold != 0\n",
    "if check_fit:\n",
    "    if fit_threshold < 0:\n",
    "        replace_rejects = False\n",
    "        fit_threshold *= -1\n",
    "    else:\n",
    "        replace_rejects = True\n",
    "else:\n",
    "    replace_rejects = False\n",
    "\n",
    "# Switches determining what needs to be calculated\n",
    "rchi2_required = get_rchi2 or check_fit\n",
    "error_required = get_error or get_cov or (\n",
    "        rchi2_required and not have_error)\n",
    "weightsum_required = (order_is_zero or get_error or\n",
    "                      rchi2_required or is_covar or get_weights)\n",
    "residual_required = rchi2_required or (error_required and not have_error)\n",
    "weight_is_variance = error_weighting and not distance_weighting\n",
    "\n",
    "\n",
    "dataset = 0\n",
    "    \n",
    "\n",
    "from pypeutils.resampling.resample_utils import mask_count\n",
    "set_mask = submask[dataset]\n",
    "counts = mask_count(set_mask)\n",
    "    \n",
    "from pypeutils.resampling.resample_utils import check_orders\n",
    "set_order = check_orders(\n",
    "    order_algorithm_idx, local_subcoord, visitor_subcoord,\n",
    "    set_mask, order,  minimum_points, required)\n",
    "    \n",
    "set_data = subdata[dataset]\n",
    "set_error = suberror[dataset]\n",
    "\n",
    "# Check if this is a zero order polynomial (mean)\n",
    "do_weightsum = weightsum_required\n",
    "do_order_zero = order_is_zero\n",
    "if check_order0:\n",
    "    for o in set_order:\n",
    "        if o != 0:\n",
    "            break\n",
    "    else:\n",
    "        do_order_zero = True\n",
    "        do_weightsum = True\n",
    "\n",
    "# Select the correct order set in the case that orders vary\n",
    "# This only works for symmetrical orders\n",
    "if order_varies:\n",
    "    oidx = order_idx[set_order[0]: set_order[0] + 2]\n",
    "    set_visitor_power = subvisitor_powers[oidx[0]: oidx[1]]\n",
    "    set_local_power = sublocal_powers[oidx[0]: oidx[1]]\n",
    "else:\n",
    "    set_visitor_power = subvisitor_powers\n",
    "    set_local_power = sublocal_powers\n",
    "    \n",
    "\n",
    "dw = dweights\n",
    "\n",
    "import math\n",
    "from pypeutils.resampling.resample_utils import prune_equation_arrays\n",
    "set_data, set_local_power, set_error, set_dweights = \\\n",
    "    prune_equation_arrays(counts, set_mask, set_data,\n",
    "                          set_local_power, set_error, dw)\n",
    "    \n",
    "from pypeutils.resampling.resample_utils import calculate_set_weights\n",
    "set_weight = calculate_set_weights(\n",
    "    set_error, set_dweights, error_weighting)\n",
    "    \n",
    "from pypeutils.resampling.resample_utils import sum_weights\n",
    "weightsum = sum_weights(set_weight)\n",
    "\n",
    "fitted, variance, rchi2, cov = solve_polynomial_fit(\n",
    "    set_data, set_error, set_weight, set_local_power,\n",
    "    set_visitor_power, weightsum, principle_idx,\n",
    "    residual_required, error_required, rchi2_required,\n",
    "    get_cov, have_error, weight_is_variance, fast_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########### SOLVE POLYNOMIAL FIT\n",
    "\n",
    "principle = principle_idx.copy()\n",
    "phi_samples = set_local_power.copy()\n",
    "phi_point = set_visitor_power.copy()\n",
    "calculate_cov = get_cov\n",
    "\n",
    "from pypeutils.resampling.resample_utils import(\n",
    "solve_amat_beta, solve_coefficients, fitted_mean, fit_residual,\n",
    "fitted_variance, principle_covariance, njit, solve_rchi2_from_error,\n",
    "solve_rchi2_from_variance\n",
    ")\n",
    "\n",
    "amat, beta = solve_amat_beta(phi_samples, set_data, set_weight)\n",
    "rank, coefficients = solve_coefficients(amat, beta)\n",
    "fitted = fitted_mean(phi_point, coefficients)\n",
    "residuals = fit_residual(set_data, phi_samples, coefficients)\n",
    "    \n",
    "measure = set_error\n",
    "    \n",
    "variance, covariance = fitted_variance(\n",
    "    measure, set_weight, amat, phi_samples, phi_point,\n",
    "    weight_is_variance, rank, fast_error)\n",
    "\n",
    "kshape = principle_covariance(covariance, principle)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a256b3810>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initial imports\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "from pypeutils.resampling.resample import *\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import warnings\n",
    "from pypeutils.resampling.resample_utils import calculate_distance_weights_matrix\n",
    "# %matplotlib inline\n",
    "\n",
    "image = np.zeros((256, 256))\n",
    "image[96:160, 96:160] = 1\n",
    "error = 1e-3\n",
    "\n",
    "noise = np.random.random(image.shape) * 1e-2\n",
    "image += noise\n",
    "\n",
    "xout, yout = np.linspace(80, 112, 32), np.linspace(80, 112, 32)\n",
    "y, x = np.mgrid[:256, :256]\n",
    "coordinates = np.stack([x.ravel(), y.ravel()])\n",
    "\n",
    "cout = np.stack([xout, np.full(32, 128)])\n",
    "\n",
    "points = np.stack([\n",
    "    [96, 128, 160,  96, 128, 160,  96, 128, 160],\n",
    "    [96,  96,  96, 128, 128, 128, 160, 160, 160]\n",
    "]).astype(float)\n",
    "\n",
    "# tl, tc, tr, ml, mc, mr, bl, bc, br\n",
    "\n",
    "xout, yout = np.arange(256), np.arange(256)\n",
    "\n",
    "resampler = Resample(coordinates, image.ravel(), order=2, window=9,\n",
    "                     error=error, mode='extrapolate')\n",
    "\n",
    "sigma = gaussian_fwhm_to_sigma * 3\n",
    "\n",
    "\n",
    "bad_point = np.array([[7.0],[108]])\n",
    "\n",
    "\n",
    "i0, w0, s0, cov = resampler(xout, yout, jobs=-1,\n",
    "                        smoothing=sigma,\n",
    "                        get_distance_weights=True,\n",
    "                        get_cov=True,\n",
    "                        get_rchi2=True)\n",
    "\n",
    "ia, wa = resampler(xout, yout, jobs=-1, smoothing=sigma,\n",
    "                        adaptive_threshold=1.0,\n",
    "                        get_distance_weights=True)\n",
    "\n",
    "\n",
    "from pypeutils.resampling.resample_utils import rescale_gradient_matrices\n",
    "from pypeutils.resampling.resample_utils import gaussian_matrix\n",
    "yg, xg = np.mgrid[:64, :64]\n",
    "xc = np.stack([xg.ravel() * 1.0, yg.ravel()]) / 16\n",
    "center = np.array([32.0, 32.0]) / 16\n",
    "\n",
    "# i = 0  # tl\n",
    "# i = 1  # tc\n",
    "# i = 2  # tr\n",
    "# i = 3  # ml\n",
    "# i = 4  # mc\n",
    "# i = 5  # mr\n",
    "# i = 6  # bl\n",
    "# i = 7  # bc\n",
    "# i = 8  # br\n",
    "\n",
    "mats = create_gaussian_matrices(cov, fixed, s0, base)\n",
    "t = mats[i]\n",
    "wg = calculate_distance_weights_matrix(xc, center, t).reshape(64, 64)\n",
    "plt.imshow(wg)\n",
    "\n",
    "\n",
    "\n",
    "# OR\n",
    "g = cov[i].copy()\n",
    "fixed = np.array([False, False])\n",
    "scale = s0[i]\n",
    "base = np.ones(2)\n",
    "\n",
    "t = gaussian_matrix(g, fixed, scale, base)\n",
    "\n",
    "\n",
    "yg, xg = np.mgrid[:64, :64]\n",
    "xc = np.stack([xg.ravel() * 1.0, yg.ravel()]) / 16\n",
    "center = np.array([32.0, 32.0]) / 16\n",
    "wg = calculate_distance_weights_matrix(xc, center, t).reshape(64, 64)\n",
    "plt.imshow(wg)\n",
    "\n",
    "\n",
    "######### OLDER\n",
    "\n",
    "for g in cov:\n",
    "    u, s, v = np.linalg.svd(g)\n",
    "    dr = np.sqrt(np.prod(s)) ** (1 / s.size)\n",
    "    print((i, dr))\n",
    "\n",
    "# Plotting\n",
    "g = cov[i].copy()\n",
    "t = g / np.abs(np.diag(g)).max()\n",
    "\n",
    "yg, xg = np.mgrid[:64, :64]\n",
    "xc = np.stack([xg.ravel() * 1.0, yg.ravel()]) / 16\n",
    "center = np.array([32.0, 32.0]) / 16\n",
    "wg = calculate_distance_weights_matrix(xc, center, t).reshape(64, 64)\n",
    "plt.imshow(wg)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}