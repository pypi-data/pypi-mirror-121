# ---------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# ---------------------------------------------------------
"""Functions used to generate Python script for customer usage."""
from typing import Any, cast, Optional, List, Tuple
import json
import os
import pickle
import shutil
import tempfile

from azureml.core import Run, Workspace
from azureml.automl.runtime import data_cleaning
from azureml.automl.runtime.featurization.transformer_and_mapper import (
    TransformerAndMapper,
)
from azureml.automl.runtime.featurization import DataTransformer
from azureml.automl.runtime.featurizer.transformer.timeseries import (
    TimeSeriesTransformer,
)
from azureml.automl.runtime.shared.model_wrappers import (
    RegressionPipeline,
    ForecastingPipelineWrapper,
    PreFittedSoftVotingClassifier,
    PreFittedSoftVotingRegressor,
    StackEnsembleBase,
)
from azureml.automl.runtime.stack_ensemble_base import Scorer
from azureml.automl.core import _codegen_utilities
from azureml.train.automl import _constants_azureml
from sklearn.pipeline import Pipeline
from sklearn_pandas import DataFrameMapper
from sklearn_pandas.pipeline import TransformerPipeline


GET_TRAIN_DATASET_FUNC_NAME = "get_training_dataset"
GET_VALID_DATASET_FUNC_NAME = "get_validation_dataset"
PREPARE_DATA_FUNC_NAME = "prepare_data"
FEATURIZE_FUNC_NAME = "generate_data_transformation_config"
PREPROC_FUNC_NAME = "generate_preprocessor_config"
MODEL_FUNC_NAME = "generate_algorithm_config"
BUILD_MODEL_FUNC_NAME = "build_model_pipeline"
TRAIN_MODEL_FUNC_NAME = "train_model"


def _get_setup_run(parent_run: Run) -> Run:
    setup_run_list = list(
        parent_run._client.run.get_runs_by_run_ids(
            run_ids=["{}_{}".format(parent_run.id, "setup")]
        )
    )
    # if this is a local run there will be no setup iteration
    if len(setup_run_list) == 0:
        setup_run = parent_run
    else:
        setup_run = setup_run_list[0]
    return setup_run


def generate_full_script(child_run: Run) -> str:
    with _codegen_utilities.use_custom_repr():
        output = [
            "# ---------------------------------------------------------",
            "# Copyright (c) Microsoft Corporation. All rights reserved.",
            "# ---------------------------------------------------------",
            "# This file has been autogenerated by the Azure Automated Machine Learning SDK.",
            "\n",
            "import numpy",
            "import pickle",
            "import joblib",
            "\n",
        ]

        parent_run = child_run.parent

        parent_run_details = parent_run.get_details()
        properties = parent_run.properties
        input_datasets = parent_run_details.get("inputDatasets", [])
        training_dataset_id = None
        validation_dataset_id = None

        for input_dataset in input_datasets:
            consumption_block = input_dataset.get("consumptionDetails", {})
            dataset_name = consumption_block.get("inputName", None)

            if dataset_name == "training_data":
                training_dataset_id = input_dataset["dataset"].id
            elif dataset_name == 'validation_data':
                validation_dataset_id = input_dataset['dataset'].id

        assert training_dataset_id is not None, "No training dataset found"

        settings_json = properties.get(_constants_azureml.Properties.AML_SETTINGS)
        settings_obj = json.loads(settings_json)
        task_type = settings_obj.get("task_type")
        label_column_name = settings_obj.get("label_column_name")
        weight_column_name = settings_obj.get("weight_column_name")

        is_timeseries = settings_obj.get("is_timeseries", False)

        # If timeseries, we will always have a TST
        featurization_enabled = (
            settings_obj.get("featurization", "off") != "off" or
            settings_obj.get("preprocess", False) is not False or
            is_timeseries
        )

        tempdir = None
        timeseries_transformer = None
        timeseries_stddev = None  # type: Optional[float]

        try:
            tempdir = tempfile.mkdtemp()

            # Retrieve the preprocessor/algorithm sklearn pipeline
            child_run.download_file(_constants_azureml.MODEL_PATH, tempdir)
            pipeline_path = os.path.join(
                tempdir, os.path.basename(_constants_azureml.MODEL_PATH)
            )
            with open(pipeline_path, "rb") as f:
                pipeline = pickle.load(f)

            if featurization_enabled:
                # Pipeline steps are tuples of (name, object)
                # If featurization ran, it should be the first step of the pipeline.
                if isinstance(pipeline.steps[0][1], DataTransformer):
                    data_transformer = pipeline.steps[0][1]
                elif isinstance(pipeline.steps[0][1], TimeSeriesTransformer):
                    timeseries_transformer = pipeline.steps[0][1]
                    timeseries_stddev = cast(float, pipeline.stddev)
                else:
                    # If featurizers are missing, then featurization didn't run even if auto featurization was set
                    featurization_enabled = False
        finally:
            if tempdir is not None:
                shutil.rmtree(tempdir, ignore_errors=True)

        output.append(get_dataset_code(GET_TRAIN_DATASET_FUNC_NAME, training_dataset_id))
        output.append("\n")
        validation_dataset_exists = validation_dataset_id is not None
        if validation_dataset_exists:
            output.append(get_dataset_code(GET_VALID_DATASET_FUNC_NAME, str(validation_dataset_id)))
            output.append("\n")
        output.append(
            get_prepare_data_code(is_timeseries, label_column_name, weight_column_name)
        )
        output.append("\n")
        if is_timeseries:
            if featurization_enabled and timeseries_transformer:
                output.append(get_timeseries_transformer_code(timeseries_transformer))
                output.append("\n")
            # The model is always the last step of the pipeline.
            output.append(
                get_model_code(
                    pipeline,
                    featurization_enabled,
                    is_timeseries=True,
                    timeseries_stddev=timeseries_stddev,
                )
            )
        else:
            if featurization_enabled:
                output.append(get_transformer_code(task_type, data_transformer))
                output.append("\n")
            output.append(
                get_model_code(pipeline, featurization_enabled, is_timeseries=False)
            )
        output.append("\n")
        output.append(get_train_model_code())
        output.append("\n")
        output.append(get_scriptrun_code(task_type, is_timeseries, validation_dataset_exists))
        output.append("\n")
        output.append("if __name__ == '__main__':")
        output.append("    main()")

        output_str = "\n".join(output)

        # Experimental auto formatting. We can't rely on this until black has a proper public API
        # See https://github.com/psf/black/issues/779
        try:
            import black

            return black.format_str(output_str, mode=black.Mode())
        except Exception:
            return output_str


def get_dataset_code(dataset_func_name: str, dataset_id: str) -> str:
    output = [
        "def {}():".format(dataset_func_name),
        "from azureml.core import Dataset, Workspace, Run",
        "",
        "ws = Run.get_context().experiment.workspace",
        "dataset = Dataset.get_by_id(workspace=ws, id='{}')".format(dataset_id),
        "return dataset.to_pandas_dataframe()",
    ]

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_prepare_data_code(
    is_timeseries: bool,
    label_column_name: str,
    weight_column_name: Optional[str] = None,
) -> str:
    # TODO: make stuff from data_transformation.py publicly visible here
    #  such as label encoding, dropping NaN, etc
    output = [
        "def {}(dataframe):".format(PREPARE_DATA_FUNC_NAME),
        "from azureml.automl.runtime import data_cleaning",
        "",
        "label_column_name = '{}'".format(label_column_name),
        "",
        "# extract the features, target and sample weight arrays",
        "y_train = dataframe[label_column_name].values",
    ]

    if weight_column_name:
        output.append("class_weights_column_name = '{}'".format(weight_column_name))
        output.append(
            "X_train = dataframe.drop([label_column_name, class_weights_column_name], axis=1)"
        )
        output.append("sample_weights = dataframe[class_weights_column_name].values")
    else:
        output.append("X_train = dataframe.drop([label_column_name], axis=1)")
        output.append("sample_weights = None")

    # TODO: Make this API public (#1277252)
    output.append(
        "X_train, y_train, sample_weights = data_cleaning._remove_nan_rows_in_X_y(X_train, y_train, sample_weights,"
        " is_timeseries={}, target_column=label_column_name)".format(is_timeseries)
    )
    output.append("return X_train, y_train, sample_weights")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_transformer_code(task_type: str, data_transformer: DataTransformer) -> str:
    featurizer_config = data_transformer.transformer_and_mapper_list
    output = ["def {}():".format(FEATURIZE_FUNC_NAME)]

    imports = {
        _codegen_utilities.get_import(DataFrameMapper),
        _codegen_utilities.get_import(DataTransformer),
        _codegen_utilities.get_import(TransformerAndMapper),
        _codegen_utilities.get_import(TransformerPipeline),
        _codegen_utilities.get_import(Pipeline),
        ("numpy", "nan", float),
    }

    if featurizer_config is not None:
        for trm in featurizer_config:
            for feature in trm.mapper.features:
                for step in feature[1].steps:
                    imports.add(_codegen_utilities.get_import(step[1]))
                    if hasattr(step[1], "_get_imports"):
                        imports.update(step[1]._get_imports())

    output.extend(_codegen_utilities.generate_import_statements(sorted(list(imports))))
    output.append("")

    output.append("transformer_and_mapper_list = []")

    if featurizer_config is not None:
        for i, trm in enumerate(featurizer_config):
            i += 1
            tr_str = "transformer{}".format(i)
            output.append("{} = {}".format(tr_str, trm.mapper.features))
            params = {"input_df": trm.mapper.input_df, "sparse": trm.mapper.sparse}
            repr_str = _codegen_utilities.generate_repr_str(
                DataFrameMapper, params, features="transformer{}".format(i)
            )
            output.append("mapper{} = {}".format(i, repr_str))
            output.append(
                "tm{0} = TransformerAndMapper(transformers={1}, mapper=mapper{0})".format(
                    i, tr_str
                )
            )
            output.append("transformer_and_mapper_list.append(tm{})".format(i))
            output.append("")

    output.append("dt = DataTransformer(task='{}')".format(task_type))
    output.append("dt.transformer_and_mapper_list = transformer_and_mapper_list")

    # TODO: Have a better way to set this without this hack (#1277252)
    #  Right now, we just dump the class and it results in a massive blob of unreadable bytestrings.
    #  Also problematic if the user changes the list of featurizers.
    output.append("dt._engineered_feature_names_class = None")
    output.append("")
    output.append("return dt")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_timeseries_transformer_code(
    timeseries_transformer: TimeSeriesTransformer,
) -> str:
    output = ["def {}():".format(FEATURIZE_FUNC_NAME)]

    imports = set(timeseries_transformer._get_imports())
    imports.add(("numpy", "nan", float))
    imports.add(_codegen_utilities.get_import(TimeSeriesTransformer))

    output.extend(_codegen_utilities.generate_import_statements(sorted(list(imports))))
    output.append("")

    output.append("transformer_list = []")

    assert timeseries_transformer.pipeline is not None
    for i, step in enumerate(timeseries_transformer.pipeline.steps):
        i += 1
        transformer = step[1]
        tr_str = "transformer{}".format(i)
        output.append("{} = {}".format(tr_str, transformer))
        output.append("transformer_list.append(('{}', {}))".format(step[0], tr_str))
        output.append("")

    output.append("pipeline = Pipeline(steps=transformer_list)")

    params = timeseries_transformer.get_params(deep=False)
    params.pop("pipeline")
    pipeline_type = params.pop("pipeline_type")
    pipeline_type_str = "{}.{}".format(
        pipeline_type.__class__.__name__, pipeline_type.name
    )

    tst_repr = _codegen_utilities.generate_repr_str(
        timeseries_transformer.__class__,
        params,
        pipeline="pipeline",
        pipeline_type=pipeline_type_str,
    )

    output.append("tst = {}".format(tst_repr))
    output.append("")
    output.append("return tst")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_model_code(
    sklearn_pipeline: Pipeline,
    featurization_enabled: bool,
    is_timeseries: bool,
    timeseries_stddev: Optional[float] = None,
) -> str:
    output = []
    model = sklearn_pipeline.steps[-1][1]
    if isinstance(model, (PreFittedSoftVotingRegressor, PreFittedSoftVotingClassifier)):
        params = model.get_params(deep=False)
        estimators = params.pop("estimators")

        pipeline_definitions = []

        # Generate one pair of functions for each estimator
        for i, estimator in enumerate(estimators):
            output += get_code_for_single_estimator(estimator[1], i)
            if pipeline_has_preprocessor(estimator[1]):
                pipeline_definitions.append(
                    "pipeline_{0} = Pipeline(steps=[('preproc', {1}_{0}()), ('model', {2}_{0}())])".format(
                        i, PREPROC_FUNC_NAME, MODEL_FUNC_NAME
                    )
                )
            else:
                pipeline_definitions.append(
                    "pipeline_{0} = Pipeline(steps=[('model', {1}_{0}())])".format(
                        i, MODEL_FUNC_NAME
                    )
                )

        # Generate the main function
        # Modified version of get_modelwrapper_code() such that instead of using the estimators
        # from the model directly, we call out to the functions we generated above
        func_output = ["def {}():".format(MODEL_FUNC_NAME)]
        imports = [
            _codegen_utilities.get_import(model.__class__),
            _codegen_utilities.get_import(Pipeline),
        ]
        if hasattr(model, "_get_imports"):
            imports.extend(model._get_imports())

        func_output.extend(_codegen_utilities.generate_import_statements(imports))
        func_output.append("")
        func_output.extend(pipeline_definitions)

        estimators_output = (
            ["["] +
            ["('model_{0}', pipeline_{0}),".format(i) for i in range(len(estimators))] +
            ["]"]
        )
        estimators_str = _codegen_utilities.indent_multiline_string(
            "\n".join(estimators_output)
        )

        repr_str = _codegen_utilities.generate_repr_str(
            model.__class__, params, estimators=estimators_str
        )
        func_output.append("algorithm = {}".format(repr_str))
        func_output.append("")
        func_output.append("return algorithm")

        code_body = "\n".join(func_output)
        output.append(_codegen_utilities.indent_multiline_string(code_body))

        output.append("\n")
        if is_timeseries:
            output.append(
                get_build_timeseries_model_pipeline_code(
                    timeseries_stddev, featurization_enabled
                )
            )
        else:
            output.append(
                get_build_model_pipeline_code(True, featurization_enabled, False)
            )
    elif isinstance(model, StackEnsembleBase):
        params = model.get_params(deep=False)
        estimators = params.pop("base_learners")
        meta_estimator = params.pop("meta_learner")

        pipeline_definitions = []

        # Generate one pair of functions for each estimator
        for i, estimator in enumerate(estimators):
            output += get_code_for_single_estimator(estimator[1], i)
            if pipeline_has_preprocessor(estimator[1]):
                pipeline_definitions.append(
                    "pipeline_{0} = Pipeline(steps=[('preproc', {1}_{0}()), ('model', {2}_{0}())])".format(
                        i, PREPROC_FUNC_NAME, MODEL_FUNC_NAME
                    )
                )
            else:
                pipeline_definitions.append(
                    "pipeline_{0} = Pipeline(steps=[('model', {1}_{0}())])".format(
                        i, MODEL_FUNC_NAME
                    )
                )

        output.append(
            get_modelwrapper_code(
                ("meta", meta_estimator),
                "meta",
                extra_imports=[_codegen_utilities.get_import(Scorer)],
            )
        )
        output.append("\n")

        # Generate the main function
        # Modified version of get_modelwrapper_code() such that instead of using the estimators
        # from the model directly, we call out to the functions we generated above
        func_output = ["def {}():".format(MODEL_FUNC_NAME)]
        imports = [
            _codegen_utilities.get_import(model.__class__),
            _codegen_utilities.get_import(Pipeline),
        ]
        if hasattr(model, "_get_imports"):
            imports.extend(model._get_imports())

        func_output.extend(_codegen_utilities.generate_import_statements(imports))
        func_output.append("")

        func_output.append("meta_learner = {1}_{0}()".format("meta", MODEL_FUNC_NAME))
        func_output.append("")
        func_output.extend(pipeline_definitions)

        estimators_output = (
            ["["] +
            ["('model_{0}', pipeline_{0}),".format(i) for i in range(len(estimators))] +
            ["]"]
        )
        estimators_str = _codegen_utilities.indent_multiline_string(
            "\n".join(estimators_output)
        )
        meta_estimator_str = "meta_learner"

        repr_str = _codegen_utilities.generate_repr_str(
            model.__class__,
            params,
            base_learners=estimators_str,
            meta_learner=meta_estimator_str,
        )
        func_output.append("algorithm = {}".format(repr_str))
        func_output.append("")
        func_output.append("return algorithm")

        code_body = "\n".join(func_output)
        output.append(_codegen_utilities.indent_multiline_string(code_body))

        output.append("\n")
        if is_timeseries:
            output.append(
                get_build_timeseries_model_pipeline_code(
                    timeseries_stddev, featurization_enabled
                )
            )
        else:
            output.append(
                get_build_model_pipeline_code(True, featurization_enabled, False)
            )
    else:
        output += get_code_for_single_estimator(sklearn_pipeline)
        has_preprocessor = pipeline_has_preprocessor(sklearn_pipeline)
        if is_timeseries:
            output.append(
                get_build_timeseries_model_pipeline_code(
                    timeseries_stddev, featurization_enabled
                )
            )
        else:
            output.append(
                get_build_model_pipeline_code(
                    False, featurization_enabled, has_preprocessor
                )
            )

    return "\n".join(output)


def get_code_for_single_estimator(
    pipeline: Pipeline, name: Optional[Any] = None
) -> List[str]:
    output = []
    if pipeline_has_preprocessor(pipeline):
        output.append(get_preprocessor_code(pipeline.steps[-2], name))
        output.append("\n")
    output.append(get_modelwrapper_code(pipeline.steps[-1], name))
    output.append("\n")
    return output


def pipeline_has_preprocessor(pipeline: Pipeline) -> bool:
    return len(pipeline.steps) > 1 and not isinstance(
        pipeline.steps[-2][1], (DataTransformer, TimeSeriesTransformer)
    )


def get_preprocessor_code(model: Tuple[str, Any], name: Optional[Any] = None) -> str:
    if name is None:
        output = ["def {}():".format(PREPROC_FUNC_NAME)]
    else:
        output = ["def {}_{}():".format(PREPROC_FUNC_NAME, name)]

    preproc_name, preproc_obj = model

    imports = [_codegen_utilities.get_import(preproc_obj.__class__)]
    if hasattr(preproc_obj, "_get_imports"):
        imports.extend(preproc_obj._get_imports())

    output.extend(_codegen_utilities.generate_import_statements(imports))
    output.append("")

    output.append("preproc = {}".format(preproc_obj))
    output.append("")
    output.append("return preproc")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_modelwrapper_code(
    model: Tuple[str, Any],
    name: Optional[Any] = None,
    extra_imports: Optional[List[Tuple[str, str, Any]]] = None,
) -> str:
    if name is None:
        output = ["def {}():".format(MODEL_FUNC_NAME)]
    else:
        output = ["def {}_{}():".format(MODEL_FUNC_NAME, name)]

    model_name, model_obj = model

    imports = [_codegen_utilities.get_import(model_obj.__class__)]
    if hasattr(model_obj, "_get_imports"):
        imports.extend(model_obj._get_imports())

    if extra_imports:
        imports.extend(extra_imports)

    output.extend(_codegen_utilities.generate_import_statements(imports))
    output.append("")

    output.append("algorithm = {}".format(model_obj))
    output.append("")
    output.append("return algorithm")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_build_model_pipeline_code(
    is_ensemble: bool, featurization_enabled: bool, has_preprocessor: bool
) -> str:
    output = ["def {}():".format(BUILD_MODEL_FUNC_NAME)]

    imports = [_codegen_utilities.get_import(Pipeline)]
    output.extend(_codegen_utilities.generate_import_statements(imports))
    output.append("")

    output.append("pipeline = Pipeline(")
    output.append("    steps=[")
    if featurization_enabled:
        output.append("           ('dt', {}()),".format(FEATURIZE_FUNC_NAME))
    if is_ensemble:
        output.append("           ('ensemble', {}())".format(MODEL_FUNC_NAME))
    else:
        if has_preprocessor:
            output.append("           ('preproc', {}()),".format(PREPROC_FUNC_NAME))
        output.append("           ('model', {}())".format(MODEL_FUNC_NAME))
    output.append("    ]")
    output.append(")")
    output.append("")
    output.append("return pipeline")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_build_timeseries_model_pipeline_code(
    stddev: Optional[float], featurization_enabled: bool
) -> str:
    output = ["def {}():".format(BUILD_MODEL_FUNC_NAME)]

    imports = [
        _codegen_utilities.get_import(Pipeline),
        _codegen_utilities.get_import(ForecastingPipelineWrapper),
    ]
    output.extend(_codegen_utilities.generate_import_statements(imports))
    output.append("")

    if featurization_enabled:
        output.append("pipeline = Pipeline(")
        output.append("    steps=[('tst', {}()),".format(FEATURIZE_FUNC_NAME))
        output.append("           ('model', {}())]".format(MODEL_FUNC_NAME))
        output.append(")")
    else:
        output.append("pipeline = Pipeline(")
        output.append("    steps=[('model', {}())]".format(MODEL_FUNC_NAME))
        output.append(")")
    output.append(
        "forecast_pipeline_wrapper = ForecastingPipelineWrapper(pipeline, stddev={})".format(
            stddev
        )
    )
    output.append("")
    output.append("return forecast_pipeline_wrapper")
    # output.append("return pipeline")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_train_model_code() -> str:
    output = [
        "def {}(X, y, sample_weights):".format(TRAIN_MODEL_FUNC_NAME),
        "model_pipeline = {}()".format(BUILD_MODEL_FUNC_NAME),
        "",
        "model = model_pipeline.fit(X, y)",
        "return model",
    ]

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_scriptrun_code(task_type: str, is_timeseries: bool, validation_dataset_exists: bool) -> str:
    output = [
        "def main():",
        "# The following code is for when running this code as part of an AzureML script run.",
        "from azureml.core import Run",
        "run = Run.get_context()",
        "",
        "df = {}()".format(GET_TRAIN_DATASET_FUNC_NAME),
        "X, y, sample_weights = {}(df)".format(PREPARE_DATA_FUNC_NAME),
        "model = {}(X, y, sample_weights)".format(TRAIN_MODEL_FUNC_NAME),
        "",
    ]

    if validation_dataset_exists:
        output.extend(
            [
                "valid_df = {}()".format(GET_VALID_DATASET_FUNC_NAME),
                "X_valid, y_valid, sample_weights_valid = {}(valid_df)".format(PREPARE_DATA_FUNC_NAME),
                "y_pred = model.{}(X_valid)".format("forecast" if is_timeseries else "predict"),
                "",
            ]
        )
    else:
        output.extend(
            [
                # TODO: this is predicting on the same data on the input (just to validate the model)
                # if validation dataset is not provided.
                #  Change this to use proper splitting.
                "y_pred = model.{}(X)".format("forecast" if is_timeseries else "predict"),
                ""
            ]
        )

    # TODO: Scoring (we need to handle the validation dataset)
    # Need to fill out the parameters
    """
    if task_type == constants.Tasks.CLASSIFICATION:
        output.extend([
            "from azureml.automl.runtime.shared.score.scoring import score_classification",
            "y_pred = model.predict(X_test)",
            "metrics = score_classification()"
        ])
    elif task_type == constants.Tasks.REGRESSION:
        output.extend([
            "from azureml.automl.runtime.shared.score.scoring import score_regression",
            "y_pred = model.predict(X_test)",
            "metrics = score_regression()"
        ])
    elif task_type == constants.Tasks.FORECASTING:
        output.extend([
            "from azureml.automl.runtime.shared.score.scoring import score_forecasting",
            "y_pred = model.forecast(X_test)",
            "metrics = score_forecasting()"
        ])
    else:
        # Other tasks are not implemented
        pass
    """

    # TODO: Emit code to log metrics

    output.extend(
        [
            "# NOTE: You may need to use joblib.load() to load the model if pickle.load() does not work.",
            "joblib.dump(model, 'model.pkl')",
            "run.upload_file('outputs/model.pkl', 'model.pkl')",
        ]
    )

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)
