import re
import os
from itertools import zip_longest
from wbnlu.utils.fileio import read_yaml_file

from opencc import OpenCC

import emoji

cc = OpenCC('t2s')
abspath = os.path.abspath(os.path.dirname(__file__))
CONFIG = read_yaml_file(os.path.join(abspath, "../configs/other_config.yml"))

TEXT_LOWER = CONFIG['TEXT_LOWER']
REMOVE_PUNCTUALTION = CONFIG['REMOVE_PUNCTUALTION']
REMOVE_ALL_SPACES = CONFIG['REMOVE_ALL_SPACES']
REMOVE_ALL_BUT_ONE_SPACES = CONFIG['REMOVE_ALL_BUT_ONE_SPACES']
REMOVE_EMOJIS = CONFIG['REMOVE_EMOJIS']

REMOVE_HASHTAG = CONFIG['REMOVE_HASHTAG']

class Text_Normalizer(object):

    def __init__(self, text):
        self.text = text
        self.name = 'normalized_text'

    def __call__(self, remove_hash=False, text_lower=False, remove_punct=False, remove_emojis=True, remove_all_space=False, remove_all_but_one_space=True, remove_urls=True):
        """

        @param text: åŸå§‹æ–‡æœ¬
        @param remove_hash: æ˜¯å¦åˆ é™¤ hash å­—ç¬¦,
        @param text_lower: æ˜¯å¦è½¬æ¢æ–‡æœ¬ä¸ºå°å†™
        @param remove_punct: æ˜¯å¦åˆ é™¤æ ‡ç‚¹ç¬¦å·
        @param remove_emojis: æ˜¯å¦åˆ é™¤æƒ…æ„Ÿå­—ç¬¦
        @param remove_all_space: æ˜¯å¦åˆ é™¤æ‰€æœ‰ç©ºæ ¼å­—ç¬¦
        @param remove_all_but_one_space: æ˜¯å¦åˆ é™¤è¿ç»­çš„ç©ºæ ¼å­—ç¬¦ï¼Œåªä¿ç•™å…¶ä¸­ä¸€ä¸ª

        æ­¤å¤–ï¼Œå½“æ­¤å‡½æ•°è¢«è°ƒç”¨æ—¶ï¼Œå‰©ä¸‹å‡ ä¸ªå‡½æ•°è‡ªåŠ¨è°ƒç”¨ï¼š
        1. remove_url: åˆ é™¤ URL
        2. remove_break_line: åˆ é™¤è¡Œåˆ†éš”ç¬¦
        3. sstrip: åˆ é™¤ç‰¹æ®Šç©ºæ ¼å­—ç¬¦ \u200b
        4. remove_junk: åˆ é™¤è„æ•°æ®
        5. qs2bs: å…¨è§’è½¬åŠè§’
        6. t2s: ç¹ä½“è½¬ç®€ä½“
        @return: æ­£è§„åŒ–çš„æ–‡æœ¬
        """
        text = self.text
        if not text:
            return " "
        if remove_urls:
            text = remove_url(text)
        text = remove_break_line(text)
        text = sstrip(text)
        text = remove_junk(text)
        text = strQ2B(text)
        text = t2s(text)
        if remove_hash:
            text = remove_hashtag(text)
        if text_lower:
            text = text.lower()
        if remove_punct:
            text = remove_punctuation(text)
        if remove_emojis:
            text = remove_emoji(text)
        if remove_all_space:
            text = remove_all_spaces(text)
        elif remove_all_but_one_space:
            text = remove_all_but_one_spaces(text)

        if not text:
            return ""
        return text.strip()


def normalize(text, remove_hash=False, text_lower=False, remove_punct=False, remove_emojis=True, remove_all_space=False, remove_all_but_one_space=True):
    if not text:
        return " "
    text = remove_url(text)
    text = remove_break_line(text)
    text = sstrip(text)
    text = remove_junk(text)
    text = qs2bs(text)
    text = t2s(text)
    if remove_hash:
        text = remove_hashtag(text)
    if text_lower:
        text = text.lower()
    if remove_punct:
        text = remove_punctuation(text)
    if remove_emojis:
        text = remove_emoji(text)
    if remove_all_space:
        text = remove_all_spaces(text)
    elif remove_all_but_one_space:
        text = remove_all_but_one_spaces(text)

    if not text:
        return ""
    return text.strip()


def t2s(text):
    return cc.convert(text)

def sstrip(text):
    text = text.replace('<U+200B>', '').strip()
    return text.replace(u'\u200b', '').strip()

def remove_emoji(text):
    allchars = [str for str in text]
    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]
    return ''.join([str for str in list(text) if not any(i in str for i in emoji_list)])

def is_emoji(text):
    return text in emoji.UNICODE_EMOJI

def remove_junk(text):
    return re.sub(ZH_JUNK_PATTERN, "", text).strip()

def remove_hashtag(text):
    return text.replace('#', '').strip()

# çŸ­å‘ ä¸­å‘ é•¿å‘ æ¯ä¸ªé•¿åº¦æ€»æœ‰ä¸€æ¬¾å‘å‹é€‚åˆ http://t.cn/AigOWB1q
def remove_url(text):
    return re.sub(URL_PATTERN, "", text).strip()

def remove_all_spaces(text):
    return re.sub(WS_PATTERN, "", text)

def remove_all_but_one_spaces(text):
    return re.sub(AT_LEAST_TWO_WS_PATTERN, " ", text).strip()

def remove_punctuation(text):
    return re.sub(ZH_PUNCT_PATTERN, "", text).strip()

def remove_break_line(text):
    return re.sub(BREAK_LINE_PATTERN, "", text).strip()

def is_ascii(string):
    return all(ord(c) < 128 for c in string)

def is_ascii_char(c):
    return ord(c) < 128

def has_ascii_char(string):
    for c in string:
        if is_ascii_char(c) and c != ' ':
            return True
    return False

def is_cjk(text):
    if re.search("[\u4e00-\u9FFF]", text):
        return True
    return False

def is_korean(text):
    re.search("[\uac00-\ud7a3]", text)

def is_japanese(text):
    re.search("[\u3040-\u30ff]", text)

def is_chinese(text):
    re.search("[\u4e00-\u9FFF]", text)

def is_hangul(char):
    value = ord(char)
    return value >= 4352 and value <= 4607

def are_hangul(string):
    return all(is_hangul(i) for i in string)

def has_hangul(string):
    return any(is_hangul(i) for i in string)

def is_unigram(text):
    return len(text) == 1

def qs2bs(text):
    new_text = ''
    for c in text:
        new_text += qc2bc(c)
    return new_text

def qc2bc(zh_char):
    assert len(zh_char) == 1
    inside_code = ord(zh_char)
    if inside_code == 0x3000:
        inside_code = 0x0020
    else:
        inside_code -= 0xfee0
    if inside_code < 0x0020 or inside_code > 0x7e:
        return zh_char
    return chr(inside_code)


def strQ2B(ustring):
    ss = []
    for s in ustring:
        rstring = ""
        prev_code = -1
        next_code = -1
        for i, uchar in enumerate(s):
            inside_code = ord(uchar)
            if inside_code == 12288:  # å…¨è§’ç©ºæ ¼ç›´æ¥è½¬æ¢
                inside_code = 32
            elif (inside_code >= 65281 and inside_code <= 65374):  # å…¨è§’å­—ç¬¦ï¼ˆé™¤ç©ºæ ¼ï¼‰æ ¹æ®å…³ç³»è½¬åŒ–
                flag1 = False
                flag2 = False
                if i < len(s)-1:
                    next_code = ord(s[i+1])
                else:
                    next_code = -1
                if (prev_code >= 0 and prev_code <= 127) or prev_code == -1:
                    flag1 = True
                if (next_code >= 0 and next_code <= 127) or next_code == -1:
                    flag2 = True
                if flag1 and flag2:
                    inside_code -= 65248
            rstring += chr(inside_code)
        ss.append(rstring)
    return ''.join(ss)

def strB2Q(ustring):
    ss = []
    for s in ustring:
        rstring = ""
        prev_code = -1
        next_code = -1
        for i, uchar in enumerate(s):
            inside_code = ord(uchar)
            if inside_code == 32:
                inside_code = 12288
            elif (inside_code >= 33 and inside_code <= 126):
                flag1 = False
                flag2 = False
                if i < len(s)-1:
                    next_code = ord(s[i+1])
                else:
                    next_code = -1
                if (prev_code >= 19968 and prev_code <= 40959) or prev_code == -1:
                    flag1 = True
                if (next_code >= 19968 and next_code <= 40959) or next_code == -1:
                    flag2 = True
                if flag1 and flag2:
                    inside_code += 65248
                    if inside_code == 65294:
                        inside_code = 12290
                prev_code = inside_code
            rstring += chr(inside_code)
        ss.append(rstring)
    return ''.join(ss)

def has_zh_words(word_list, text):
    for word in word_list:
        if word in text:
            return True
    return False

def split_keep_delimiter(line):
    sentences = []
    lines = re.split(ZH_SEG_PUNCT_CHARS_PATTERN, line)
    for a,b in zip_longest(lines[::2],lines[1::2]):
        r = a+(b if b else '')
        sentences.append(r)
    new_sentences = []
    for sentence in sentences:
        sentence = sentence.replace('\\n','\n')
        new_sentences.append(sentence)

    return new_sentences

def unit_exchange(text):
    if text.find('cm'):
        index = text.find('cm')
        if not is_chinese(text[index-1]):
            text = text[:index]+'å˜ç±³'+text[index+2:]
    return text


WS_PATTERN = re.compile(r"\s+")
BREAK_LINE_PATTERN = re.compile(r"[\t\r\n]")
AT_LEAST_TWO_WS_PATTERN = re.compile(r"\s{2,}")

# context = re.sub("[\s+\.\!\/_,$%^*(+\"\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰]+".decode("utf8"), "",context)
# context = re.sub("[ã€ã€‘â•®â•¯â–½â•°â•­â˜…â†’ã€Œã€]+".decode("utf8"),"",context)
# context = re.sub("ï¼ï¼Œâ¤ã€‚ï½ã€Šã€‹ï¼šï¼ˆï¼‰ã€ã€‘ã€Œã€ï¼Ÿâ€â€œï¼›ï¼šã€".decode("utf8"),"",context)

URL_PATTERN = re.compile(r"https?:[^\s]+[a-zA-Z0-9]")
ZH_SEG_PUNCT_CHARS = ["ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "!", "?"]
ZH_SEG_PUNCT_CHARS_PATTERN = re.compile(r"([ã€‚ï¼ï¼Ÿ,ï¼›!?\n])")
ZH_PUNCT_PATTERN = re.compile(r"[ã€‚ï¼Œï¼ï¼Ÿï¼›,!?.ã€ã€‘~â€œâ€@Â·â•®â•¯â–½â•°â•­â˜…â†’ã€Œã€/~â€¦&*+â€”^â¤ï½ã€Šã€‹ï¼šï¼ˆï¼‰\]\[\u200b]")
ZH_JUNK_PATTERN = re.compile(r"[î„â—îŒ±~ã€œÂ·â•®â•¯â–½â•°â•­â˜…â†’â€¦&*^â¤ï½\u200b\xa0]")
TFIDF_TERM_PATTERN = re.compile('([^\s]+)\s+(\d+)\s+\d+\s+(\d+\.\d+)')
# çœ¼å½±                    467798    16536                     0.000181422351233672      		é¢è†œ                    634692
TF_TERM_PATTERN = re.compile('[^\s]+\s+\d+\s+\d+\s+\d+\.\d+\s+([^\s]+)+\s+(\d+)')

if __name__ == "__main__":
    # str = "Fish Marketğ“†ğ“†Ÿğ“†œğ“†ğ“†¡ğ“†ğ“†Ÿğ“†œğ“†ğ“†¡ "
    # print(str)
    # print(remove_emoji(str))

    # text = "çŸ­å‘ ä¸­å‘ é•¿å‘ æ¯ä¸ªé•¿åº¦æ€»æœ‰ä¸€æ¬¾å‘å‹é€‚åˆ http://t.cn/AigOWB1q"
    # print(remove_url(text))

    # text = "çŸ­å‘  ä¸­å‘ é•¿å‘"
    # print(remove_all_but_one_spaces(text))

    text = "å§å¦¹ä»¬ï¼Œæ€ä¹ˆæŠŠå‡ ç« æ¯›è´´ æˆå¤ª é˜³èŠ±å‘¢ï¼Ÿ"
    print(remove_all_spaces(text))

    # text = "å”‡è†.."
    # print(remove_punctuation(text))

    # text = 'çº¢'
    # print(is_ascii_char(text))

    # s = 'ç§è‰ â€‹'
    # print(len(s))
    # s = remove_punctuation(s)
    # print(len(s))

    # text = 'é•¿å‘ æ¯ä¸ªé•¿åº¦.ã€â€@â€œâ€@Â·â•®â•¯â–½â•°â•­â˜…â†’ã€Œã€/$~#ï¿¥%â€¦&*+â€”^â¤ï½ã€Šã€‹ï¼šï¼ˆï¼‰\u200b'

    # print(remove_punctuation(text))

    # print(remove_break_line('å¤´è¦å˜å¾—è¶Šä½ã€‚ \n\nè¢«ç§°ä¸º'))

    # str = "Fish Marketğ“†ğ“†Ÿğ“†œğ“†ğ“†¡ğ“†ğ“†Ÿğ“†œğ“†ğ“†¡ "
    # print(str)
    # print(remove_emoji(str))

    # str = 'ã€‚ ï¼› ï¼Œ'
    # str2 = qs2bs(str)
    # print(len(str2), len(str))

    str = 'æ¤’å¡æœ«èŠ‚0åˆ†ï¼Œé‡Œå¼—æ–¯å†æ¬¡è¢«3ï¼š1ç¿»èˆ¹ã€‚'
    print ('Quan 2 ban: ', str, ' -> ',strQ2B(str))

    str = 'æˆ‘æ¥äº†,æˆ‘æ¥äº†.'
    print ('Ban 2 quan: ', str, ' -> ', strB2Q(str))

    str = 'åšç­çš„æ‰‹æŒï¼ˆ27.3cmï¼‰'
    print ('Unit: ', str, ' -> ', unit_exchange(str))
