#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : aizoo.
# @File         : oof
# @Time         : 2021/9/14 ä¸‹åˆ3:42
# @Author       : yuanjie
# @WeChat       : 313303303
# @Software     : PyCharm
# @Description  : todo: å¢žåŠ nnæ¨¡åž‹


from meutils.pipe import *
from sklearn.model_selection import ShuffleSplit, StratifiedKFold


class OOF(object):

    def __init__(self, params=None, fit_params=None, weight_func=None, task='Classifier', importance_type='split'):
        """

        @param params:
        @param fit_params:
        @param weight_func:
        @param task: Classifier or Regressor
        """
        self.params = params if params is not None else {}
        self.fit_params = fit_params if fit_params is not None else {}
        self.weight_func = weight_func

        self.task = task.title()

        self._estimators = []  # æ¯ä¸€æŠ˜çš„æ¨¡åž‹
        self._importance_type = importance_type
        self.feature_importances_ = None

    @abstractmethod
    def fit_predict(self, X_train, y_train, X_valid, y_valid, X_test, **kwargs):
        raise NotImplementedError

    def predict(self, X):
        preds = []

        for estimator in self._estimators:
            if hasattr(estimator, 'predict_proba'):
                preds.append(estimator.predict_proba(X))
            else:
                preds.append(estimator.predict(X))

        return np.array(preds).mean(0)

    def fit(self, X, y, X_test=None, feval=None, cv=5, split_seed=777, oof_file=None):

        X_test = X_test if X_test is not None else X[:66]

        self.feature_importances_ = np.zeros((cv, X.shape[1]))

        if self.task == 'Regressor':  # ç›®æ ‡å€¼å¤šäºŽ128ä¸ªå°±è®¤ä¸ºæ˜¯å›žå½’é—®é¢˜ len(set(y)) > 128
            self.oof_train_proba = np.zeros(len(X))
            self.oof_test_proba = np.zeros(len(X_test))
            _ = enumerate(ShuffleSplit(cv, random_state=split_seed).split(X, y))

        elif self.task == 'Classifier':
            num_classes = len(set(y))
            assert num_classes < 128, "æ˜¯å¦æ˜¯åˆ†ç±»é—®é¢˜"
            self.oof_train_proba = np.zeros([len(X), num_classes])
            self.oof_test_proba = np.zeros([len(X_test), num_classes])
            _ = enumerate(StratifiedKFold(cv, shuffle=True, random_state=split_seed).split(X, y))
        else:
            raise ValueError("TaskTypeErrorâš ï¸")

        valid_metrics = []
        for n_fold, (train_index, valid_index) in tqdm(_, desc='TrainðŸ”¥'):
            print(f"\033[94mFold {n_fold + 1} started at {time.ctime()}\033[0m")
            X_train, y_train = X[train_index], y[train_index]
            X_valid, y_valid = X[valid_index], y[valid_index]

            ##############################################################
            valid_predict, test_predict = self.fit_predict(X_train, y_train, X_valid, y_valid, X_test)
            ##############################################################

            self.oof_train_proba[valid_index] = valid_predict
            self.oof_test_proba += test_predict / cv

            # è®°å½•ç‰¹å¾é‡è¦æ€§
            self.feature_importances_[n_fold] = self._get_imp(self._estimators[-1], X_train, self._importance_type)

            if feval is not None:
                if self.oof_test_proba.shape[1] == 2:  # todo: ç›®å‰ä¸æ”¯æŒå¤šåˆ†ç±»
                    valid_metrics.append(feval(y_valid, valid_predict[:, 1]))  # äºŒåˆ†ç±»
                else:
                    valid_metrics.append(feval(y_valid, valid_predict))  # å›žå½’

        if self.oof_test_proba.shape[1] == 2:
            self.oof_train_proba = self.oof_train_proba[:, 1]
            self.oof_test_proba = self.oof_test_proba[:, 1]

        self.oof_train_test = np.r_[self.oof_train_proba, self.oof_test_proba]  # æ–¹ä¾¿åŽç»­stacking

        if feval is not None:
            self.oof_score = feval(y, self.oof_train_proba)

            print("\n\033[94mScore Info:\033[0m")
            print(f"\033[94m     {cv:>2} CV: {self.oof_score:.6f}\033[0m")

            _ = np.array(valid_metrics)
            print(f"\033[94m     Valid: {_.mean():.6f} +/- {_.std():.6f} \033[0m\n")

            return self.oof_score

        if oof_file is not None:
            pd.DataFrame({'oof': self.oof_train_test}).to_csv(oof_file, index=False)

    @classmethod
    def opt_cv(cls, X, y, X_test=None, cv_list=range(3, 16), params=None, **run_kwargs):
        """todo: æŠ˜æ•°ä¼˜åŒ–"""

        scores = []
        for cv in tqdm(cv_list, desc='opt cvðŸ”¥'):  # range(3, 16):
            oof = cls(params)
            oof.fit(X, y, X_test, **run_kwargs)
            scores.append((oof.oof_score, cv, oof))

        return sorted(scores)[::-1]

    def plot_feature_importances(self, feature_names=None, topk=20, figsize=None, pic_name=None):
        import seaborn as sns
        import matplotlib.pyplot as plt

        columns = ['Importances', 'Features']
        importances = self.feature_importances_.mean(0)

        if feature_names is None:
            feature_names = list(map(lambda x: f'F_{x}', range(len(importances))))

        _ = sorted(zip(importances, feature_names), reverse=True)
        self.df_feature_importances = pd.DataFrame(_, columns=columns)

        plt.figure(figsize=(14, topk // 5) if figsize is None else figsize)
        sns.barplot(x=columns[0], y=columns[1], data=self.df_feature_importances[:topk])
        plt.title(f'Features {self._importance_type.title()} Importances')
        plt.tight_layout()
        if pic_name is not None:
            plt.savefig(f'importances_{self.oof_score}.png')

    @staticmethod
    def _get_imp(estimator, X=None, importance_type=None):

        if importance_type in (None, 'tree', 'gini', 'split', 'gain'):
            imp = estimator.feature_importances_

        elif importance_type in ('shap', 'Shap'):
            import shap
            explainer = shap.Explainer(estimator)
            shap_values = explainer(X).values

            if shap_values.ndim == 2:
                imp = np.abs(shap_values).mean(0)
            else:
                imp = np.abs(shap_values).mean(0).sum(1)

            # if isinstance(coefs, list):
            #     coefs = list(map(lambda x: np.abs(x).mean(0), coefs))
            #     coefs = np.sum(coefs, axis=0)
            # else:
            #     coefs = np.abs(coefs).mean(0)

        else:
            imp = ...

        return imp
